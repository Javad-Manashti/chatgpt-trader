{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fetching forex data from 2024-06-05T22:04:49Z to 2024-06-09T22:04:49Z with granularity M15 for instrument EUR_USD\n",
      "INFO:root:Sending data to OpenAI API for analysis\n",
      "INFO:root:Data tokens before adding image: 58134, Estimated Data Cost: $0.290670\n",
      "INFO:root:OpenAI API Analysis Result: {\n",
      "    \"id\": \"chatcmpl-9YKweqs88FzxpWlrtRBiZikvPHEw9\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1717970692,\n",
      "    \"model\": \"gpt-4o-2024-05-13\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"```json\\n{\\n    \\\"orders\\\": [\\n        {\\n            \\\"timeframe\\\": \\\"60 minutes\\\",\\n            \\\"pattern_name\\\": \\\"Bullish RSI Divergence\\\",\\n            \\\"confidence_percentage\\\": 85,\\n            \\\"action\\\": \\\"BUY\\\",\\n            \\\"entry_price\\\": 1.0869,\\n            \\\"take_profit\\\": 1.0895,\\n            \\\"stop_loss\\\": 1.0840,\\n            \\\"profit_loss_ratio\\\": 2.67,\\n            \\\"deadline_date\\\": \\\"2023-10-10T12:00:00Z\\\"\\n        },\\n        {\\n            \\\"timeframe\\\": \\\"30 minutes\\\",\\n            \\\"pattern_name\\\": \\\"MACD Bullish Crossover\\\",\\n            \\\"confidence_percentage\\\": 75,\\n            \\\"action\\\": \\\"BUY\\\",\\n            \\\"entry_price\\\": 1.0872,\\n            \\\"take_profit\\\": 1.0890,\\n            \\\"stop_loss\\\": 1.0850,\\n            \\\"profit_loss_ratio\\\": 2.25,\\n            \\\"deadline_date\\\": \\\"2023-10-10T12:30:00Z\\\"\\n        }\\n    ],\\n    \\\"best_pattern\\\": {\\n        \\\"pattern_name\\\": \\\"Bullish RSI Divergence\\\",\\n        \\\"confidence_percentage\\\": 85,\\n        \\\"action\\\": \\\"BUY\\\",\\n        \\\"entry_price\\\": 1.0869,\\n        \\\"take_profit\\\": 1.0895,\\n        \\\"stop_loss\\\": 1.0840,\\n        \\\"profit_loss_ratio\\\": 2.67,\\n        \\\"deadline_date\\\": \\\"2023-10-10T12:00:00Z\\\"\\n    }\\n}\\n```\"\n",
      "            },\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\"\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 58141,\n",
      "        \"completion_tokens\": 321,\n",
      "        \"total_tokens\": 58462\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_319be4768e\"\n",
      "}\n",
      "INFO:root:Response received: 321 tokens, Cost: $0.004815\n",
      "INFO:root:Prompt sent: 58141 tokens, Cost: $2.907050\n",
      "INFO:root:Order Details - Action: BUY, Entry Price: 1.0869, Take Profit: 1.0895, Stop Loss: 1.084\n",
      "INFO:root:Order placed successfully: {'orderCreateTransaction': {'id': '153', 'accountID': '101-002-7656987-005', 'userID': 7656987, 'batchID': '153', 'requestID': '115292082446316572', 'time': '2024-06-09T22:05:02.894088603Z', 'type': 'MARKET_ORDER', 'instrument': 'EUR_USD', 'units': '10000', 'timeInForce': 'FOK', 'positionFill': 'DEFAULT', 'takeProfitOnFill': {'price': '1.08950', 'timeInForce': 'GTC'}, 'stopLossOnFill': {'price': '1.08400', 'timeInForce': 'GTC', 'triggerMode': 'TOP_OF_BOOK'}, 'reason': 'CLIENT_ORDER'}, 'orderCancelTransaction': {'id': '154', 'accountID': '101-002-7656987-005', 'userID': 7656987, 'batchID': '153', 'requestID': '115292082446316572', 'time': '2024-06-09T22:05:02.894088603Z', 'type': 'ORDER_CANCEL', 'orderID': '153', 'reason': 'STOP_LOSS_ON_FILL_LOSS'}, 'relatedTransactionIDs': ['153', '154'], 'lastTransactionID': '154'}\n",
      "INFO:root:Order 153 was canceled: STOP_LOSS_ON_FILL_LOSS\n",
      "INFO:root:Order placed based on analysis.\n",
      "INFO:root:Total cost for this run: Data: $0.290670, Image: $0.001275, Response: $0.004815, Total: $0.296760\n",
      "INFO:root:Waiting for 30 minutes before next run...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.contrib.factories import InstrumentsCandlesFactory\n",
    "from oandapyV20.contrib.requests import MarketOrderRequest, TakeProfitDetails, StopLossDetails\n",
    "from oandapyV20.endpoints.orders import OrderCreate\n",
    "from oandapyV20.exceptions import V20Error\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OANDA API configuration\n",
    "access_token = os.getenv('OANDA_API_TOKEN')\n",
    "account_id = os.getenv('OANDA_ACCOUNT_ID')\n",
    "api = API(access_token=access_token, environment=\"practice\")\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"oandapyV20\").setLevel(logging.WARNING)\n",
    "\n",
    "# Parameters for real-time data fetching and processing\n",
    "granularity = 'M15'  # 15 minutes granularity\n",
    "instrument = 'EUR_USD'\n",
    "pair = 'EUR_USD'\n",
    "timeframe = '15 minutes'\n",
    "window_size = 576  # Adjust window size for detecting single patterns\n",
    "step_size = 5      # Adjust step size accordingly\n",
    "\n",
    "def fetch_forex_data(from_date, to_date, granularity, instrument):\n",
    "    logging.info(f\"Fetching forex data from {from_date} to {to_date} with granularity {granularity} for instrument {instrument}\")\n",
    "    params = {\n",
    "        \"granularity\": granularity,\n",
    "        \"from\": from_date,\n",
    "        \"to\": to_date\n",
    "    }\n",
    "    data = []\n",
    "    try:\n",
    "        for request in InstrumentsCandlesFactory(instrument=instrument, params=params):\n",
    "            response = api.request(request)\n",
    "            if response:\n",
    "                for candle in response.get('candles'):\n",
    "                    rec = {\n",
    "                        'time': candle.get('time')[0:19],\n",
    "                        'complete': candle['complete'],\n",
    "                        'open': float(candle['mid']['o']),\n",
    "                        'high': float(candle['mid']['h']),\n",
    "                        'low': float(candle['mid']['l']),\n",
    "                        'close': float(candle['mid']['c']),\n",
    "                        'volume': candle['volume'],\n",
    "                    }\n",
    "                    data.append(rec)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred fetching data: {e}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def calculate_rsi(data, length=14):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=length).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=length).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(data, fast_period=12, slow_period=26, signal_period=9):\n",
    "    fast_ema = data.ewm(span=fast_period, adjust=False).mean()\n",
    "    slow_ema = data.ewm(span=slow_period, adjust=False).mean()\n",
    "    macd = fast_ema - slow_ema\n",
    "    signal = macd.ewm(span=signal_period, adjust=False).mean()\n",
    "    return macd, signal\n",
    "\n",
    "def calculate_bollinger_bands(data, window=20, no_of_std=2):\n",
    "    rolling_mean = data.rolling(window).mean()\n",
    "    rolling_std = data.rolling(window).std()\n",
    "    upper_band = rolling_mean + (rolling_std * no_of_std)\n",
    "    lower_band = rolling_mean - (rolling_std * no_of_std)\n",
    "    return rolling_mean, upper_band, lower_band\n",
    "\n",
    "def calculate_fibonacci_retracement(data):\n",
    "    max_price = data['high'].max()\n",
    "    min_price = data['low'].min()\n",
    "    diff = max_price - min_price\n",
    "    levels = [max_price - diff * r for r in [0.236, 0.382, 0.5, 0.618, 0.786]]\n",
    "    return levels\n",
    "\n",
    "def plot_candlestick_chart(df, filename):\n",
    "    df.index = pd.to_datetime(df['time'])\n",
    "    df.index.name = 'Date'\n",
    "    df['SMA20'] = df['close'].rolling(window=20).mean()\n",
    "    df['SMA50'] = df['close'].rolling(window=50).mean()\n",
    "    df['RSI'] = calculate_rsi(df['close'])\n",
    "\n",
    "    # Correct calculation for support and resistance\n",
    "    support = df['low'].rolling(window=20).min()\n",
    "    resistance = df['high'].rolling(window=20).max()\n",
    "\n",
    "    mc = mpf.make_marketcolors(up='green', down='red', wick={'up':'green', 'down':'red'}, edge={'up':'green', 'down':'red'})\n",
    "    s = mpf.make_mpf_style(marketcolors=mc, gridstyle='--')\n",
    "    \n",
    "    addplots = [\n",
    "        mpf.make_addplot(df['SMA20'], color='blue'),\n",
    "        mpf.make_addplot(df['SMA50'], color='orange'),\n",
    "        mpf.make_addplot(df['RSI'], panel=1, color='purple', ylabel='RSI'),\n",
    "        mpf.make_addplot(support, color='green', linestyle='dashed'),\n",
    "        mpf.make_addplot(resistance, color='red', linestyle='dashed'),\n",
    "    ]\n",
    "    \n",
    "    kwargs = dict(type='candle', style=s, addplot=addplots, volume=True, figscale=1.0, figratio=(10, 10), title=pair, ylabel='Price')\n",
    "    mpf.plot(df, **kwargs, savefig=dict(fname=filename, dpi=100, pad_inches=0.1))\n",
    "\n",
    "def compress_image(input_path, output_path, quality=85):\n",
    "    with Image.open(input_path) as img:\n",
    "        img = img.convert('RGB')  # Convert to RGB\n",
    "        img = img.resize((510, 510), Image.LANCZOS)  # Resize to 510x510\n",
    "        img.save(output_path, 'JPEG', quality=quality)  # Save with reduced quality\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def save_prompt_to_txt(prompt_content, filename):\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(prompt_content, file, indent=4)\n",
    "\n",
    "def analyze_data_with_gpt4o(indicators_summary, image_base64):\n",
    "    logging.info(\"Sending data to OpenAI API for analysis\")\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "    \n",
    "    prompt_content = {\n",
    "        \"content\": \"Analyze the indicators data for EUR/USD and provide order details with profit/loss greater than 2. Combine all patterns found and aggregate them to find the best pattern with the highest probability, most profit/loss, and strongest win signs. The patterns should not be in the past and should happen now or in the near future. Dont send any descriotions or extra text.\\n\\n\"\n",
    "                   \"Provide the analysis in JSON format with the following structure:\\n\\n\"\n",
    "                   \"{\\n\"\n",
    "                   \"    \\\"orders\\\": [\\n\"\n",
    "                   \"        {\\n\"\n",
    "                   \"            \\\"timeframe\\\": \\\"# minutes\\\",\\n\"\n",
    "                   \"            \\\"pattern_name\\\": \\\"Pattern Name\\\",\\n\"\n",
    "                   \"            \\\"confidence_percentage\\\": ##,\\n\"\n",
    "                   \"            \\\"action\\\": \\\"####\\\",\\n\"\n",
    "                   \"            \\\"entry_price\\\": #.####,\\n\"\n",
    "                   \"            \\\"take_profit\\\": #.####,\\n\"\n",
    "                   \"            \\\"stop_loss\\\": #.####,\\n\"\n",
    "                   \"            \\\"profit_loss_ratio\\\": ##,\\n\"\n",
    "                   \"            \\\"deadline_date\\\": \\\"####-##-##T##:##:##Z\\\"\\n\"\n",
    "                   \"        }\\n\"\n",
    "                   \"    ],\\n\"\n",
    "                   \"    \\\"best_pattern\\\": {\\n\"\n",
    "                   \"        \\\"pattern_name\\\": \\\"Pattern Name\\\",\\n\"\n",
    "                   \"        \\\"confidence_percentage\\\": ##,\\n\"\n",
    "                   \"        \\\"action\\\": \\\"####\\\",\\n\"\n",
    "                   \"        \\\"entry_price\\\": #.####,\\n\"\n",
    "                   \"            \\\"take_profit\\\": #.####,\\n\"\n",
    "                   \"            \\\"stop_loss\\\": #.####,\\n\"\n",
    "                   \"            \\\"profit_loss_ratio\\\": ##,\\n\"\n",
    "                   \"            \\\"deadline_date\\\": \\\"####-##-##T##:##:##Z\\\"\\n\"\n",
    "                   \"    }\\n\"\n",
    "                   \"}\\n\",\n",
    "        \"image\": f\"data:image/png;base64,{image_base64}\",\n",
    "        \"indicators_summary\": indicators_summary\n",
    "    }\n",
    "\n",
    "    # Calculate tokens before adding image\n",
    "    enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "    num_tokens = len(enc.encode(json.dumps(prompt_content)))\n",
    "    data_cost = num_tokens * 0.000005\n",
    "    image_cost = 0.001275  # Fixed image cost based on 512x512 px\n",
    "    \n",
    "    logging.info(f\"Data tokens before adding image: {num_tokens}, Estimated Data Cost: ${data_cost:.6f}\")\n",
    "\n",
    "    save_prompt_to_txt(prompt_content, 'final_prompt.txt')\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": json.dumps(prompt_content)\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 3000\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    try:\n",
    "        response_data = response.json()\n",
    "        return response_data, data_cost, image_cost\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(\"Failed to decode JSON response from OpenAI API\")\n",
    "        return None, data_cost, image_cost\n",
    "\n",
    "def extract_and_place_order(response_data):\n",
    "    if not response_data or \"choices\" not in response_data:\n",
    "        logging.error(\"Invalid response data\")\n",
    "        return None\n",
    "\n",
    "    content = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    start_index = content.find('{')\n",
    "    end_index = content.rfind('}') + 1\n",
    "    json_content = content[start_index:end_index]\n",
    "    \n",
    "    try:\n",
    "        analysis = json.loads(json_content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Failed to parse JSON content: {e}\")\n",
    "        return None\n",
    "    \n",
    "    orders = analysis.get(\"orders\", [])\n",
    "    best_pattern = analysis.get(\"best_pattern\", {})\n",
    "    \n",
    "    for order in orders:\n",
    "        if order.get(\"profit_loss_ratio\", 0) > 2:\n",
    "            logging.info(f\"Order Details - Action: {order['action']}, Entry Price: {order['entry_price']}, Take Profit: {order['take_profit']}, Stop Loss: {order['stop_loss']}\")\n",
    "            \n",
    "            order_details = {\n",
    "                'action': order['action'],\n",
    "                'entry_price': order['entry_price'],\n",
    "                'take_profit': order['take_profit'],\n",
    "                'stop_loss': order['stop_loss'],\n",
    "                'deadline_date': order['deadline_date']\n",
    "            }\n",
    "            response = place_order(order_details)\n",
    "            \n",
    "            if 'orderCancelTransaction' in response:\n",
    "                logging.info(f\"Order {response['orderCancelTransaction']['orderID']} was canceled: {response['orderCancelTransaction']['reason']}\")\n",
    "            return order_details\n",
    "\n",
    "    logging.info(f\"Best Pattern Details - Action: {best_pattern['action']}, Entry Price: {best_pattern['entry_price']}, Take Profit: {best_pattern['take_profit']}, Stop Loss: {best_pattern['stop_loss']}\")\n",
    "    return best_pattern\n",
    "\n",
    "def place_order(order_details):\n",
    "    instrument = \"EUR_USD\"\n",
    "    \n",
    "    mkt_order = MarketOrderRequest(\n",
    "        instrument=instrument,\n",
    "        units=-10000 if order_details['action'].upper() == 'SELL' else 10000,\n",
    "        takeProfitOnFill=TakeProfitDetails(price=order_details['take_profit']).data,\n",
    "        stopLossOnFill=StopLossDetails(price=order_details['stop_loss']).data\n",
    "    )\n",
    "    \n",
    "    r = OrderCreate(accountID=account_id, data=mkt_order.data)\n",
    "    try:\n",
    "        response = api.request(r)\n",
    "        logging.info(f\"Order placed successfully: {response}\")\n",
    "        return response\n",
    "    except V20Error as e:\n",
    "        logging.error(f\"Error placing order: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def save_data_to_csv(data, filename):\n",
    "    data.to_csv(filename, index=False)\n",
    "\n",
    "# Main execution\n",
    "while True:\n",
    "    start_time = (datetime.now(timezone.utc) - timedelta(days=4)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    prices = fetch_forex_data(start_time, end_time, granularity, instrument)\n",
    "\n",
    "    # Calculate indicators\n",
    "    prices['RSI'] = calculate_rsi(prices['close'])\n",
    "    prices['MACD'], prices['MACD_Signal'] = calculate_macd(prices['close'])\n",
    "    prices['Bollinger_Mid'], prices['Bollinger_Upper'], prices['Bollinger_Lower'] = calculate_bollinger_bands(prices['close'])\n",
    "    prices['Fibonacci'] = pd.Series(calculate_fibonacci_retracement(prices))\n",
    "\n",
    "    save_data_to_csv(prices, 'forex_data_and_indicators.csv')\n",
    "\n",
    "    # Collect all the data points\n",
    "    indicators_summary = {\n",
    "        \"ClosePrices\": np.round(prices['close'], 4).to_list(),\n",
    "        \"Volume\": prices['volume'].to_list(),\n",
    "        \"RSI\": np.round(prices['RSI'], 2).to_list(),\n",
    "        \"MACD\": np.round(prices['MACD'], 4).to_list(),\n",
    "        \"MACD_Signal\": np.round(prices['MACD_Signal'], 4).to_list(),\n",
    "        \"Bollinger_Bands\": {\n",
    "            \"Middle\": np.round(prices['Bollinger_Mid'], 4).to_list(),\n",
    "            \"Upper\": np.round(prices['Bollinger_Upper'], 4).to_list(),\n",
    "            \"Lower\": np.round(prices['Bollinger_Lower'], 4).to_list()\n",
    "        },\n",
    "        \"Fibonacci\": np.round(prices['Fibonacci'], 4).to_list()\n",
    "    }\n",
    "\n",
    "    # Plot and encode the image\n",
    "    filename = \"normal_chart.png\"\n",
    "    compressed_filename = \"compressed_chart.jpg\"\n",
    "    plot_candlestick_chart(prices, filename)  # Use color image\n",
    "    compress_image(filename, compressed_filename, quality=85)  # Compress without grayscale\n",
    "    image_base64 = encode_image(compressed_filename)\n",
    "    image_size_kb = len(base64.b64decode(image_base64)) / 1024\n",
    "\n",
    "    analysis_result, data_cost, image_cost = analyze_data_with_gpt4o(indicators_summary, image_base64)\n",
    "    logging.info(f\"OpenAI API Analysis Result: {json.dumps(analysis_result, indent=4)}\")\n",
    "\n",
    "    if analysis_result:\n",
    "        response_tokens = analysis_result[\"usage\"][\"completion_tokens\"]\n",
    "        response_cost = response_tokens * 0.000015  # Adjust based on actual token cost\n",
    "        logging.info(f\"Response received: {response_tokens} tokens, Cost: ${response_cost:.6f}\")\n",
    "\n",
    "        prompt_tokens = analysis_result[\"usage\"][\"prompt_tokens\"]\n",
    "        prompt_cost = prompt_tokens * 0.00005  # Adjust based on actual token cost\n",
    "        logging.info(f\"Prompt sent: {prompt_tokens} tokens, Cost: ${prompt_cost:.6f}\")\n",
    "\n",
    "        order_details = extract_and_place_order(analysis_result)\n",
    "    \n",
    "        if order_details:\n",
    "            logging.info(\"Order placed based on analysis.\")\n",
    "    \n",
    "    total_cost = data_cost + response_cost + image_cost\n",
    "    logging.info(f\"Total cost for this run: Data: ${data_cost:.6f}, Image: ${image_cost:.6f}, Response: ${response_cost:.6f}, Total: ${total_cost:.6f}\")\n",
    "\n",
    "    logging.info(\"Waiting for 30 minutes before next run...\")\n",
    "    time.sleep(1800)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
