{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v20\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.contrib.factories import InstrumentsCandlesFactory\n",
    "import os\n",
    "import mplfinance as mpf\n",
    "import openai\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OANDA API configuration using environment variables\n",
    "api = v20.Context(\n",
    "    hostname='api-fxpractice.oanda.com',\n",
    "    port=443,\n",
    "    ssl=True,\n",
    "    token=os.getenv('OANDA_API_TOKEN'),\n",
    "    datetime_format='RFC3339'\n",
    ")\n",
    "access_token = os.getenv('OANDA_API_TOKEN')\n",
    "\n",
    "# Set OpenAI API key from environment variables\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Ensure all your imports and configurations are correct, including the fetch_forex_data function\n",
    "\n",
    "\n",
    "def fetch_and_process_realtime_data(granularity, instrument, pair, timeframe, base_dir, window_size, step_size):\n",
    "    end_time = (datetime.now(timezone.utc) - timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    start_time = (datetime.now(timezone.utc) - timedelta(days=4)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    logging.info(f\"Fetching initial data from {start_time} to {end_time}\")\n",
    "    initial_prices = fetch_forex_data(start_time, end_time, granularity, instrument)\n",
    "\n",
    "    if initial_prices.empty:\n",
    "        logging.error(\"No initial data fetched. Exiting.\")\n",
    "        return\n",
    "\n",
    "    create_moving_window_charts(initial_prices, 1000, step_size, base_dir)\n",
    "\n",
    "    while True:\n",
    "        end_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        start_time = (datetime.now(timezone.utc) - timedelta(minutes=5 * 576 / 12)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        logging.info(f\"Fetching data from {start_time} to {end_time}\")\n",
    "        prices = fetch_forex_data(start_time, end_time, granularity, instrument)\n",
    "        \n",
    "        if prices.empty:\n",
    "            logging.error(\"No data fetched. Retrying in 5 minutes.\")\n",
    "        else:\n",
    "            create_moving_window_charts(prices, window_size, step_size, base_dir)\n",
    "        \n",
    "        logging.info(\"Sleeping for 5 minutes before fetching new data\")\n",
    "        time.sleep(300)\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Example usage with variables for the date range\n",
    "# end_time = (datetime.now(timezone.utc) - timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "# start_time = (datetime.now(timezone.utc) - timedelta(days=4)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "# print(start_time)\n",
    "# print(end_time)\n",
    "# logging.info(f\"Fetching data from {start_time} to {end_time}\")\n",
    "\n",
    "# prices = fetch_forex_data(start_time, end_time, 'M15', 'EUR_USD')\n",
    "# logging.info(prices.head())\n",
    "\n",
    "# # prices = fetch_forex_data('2024-05-14T00:00:00Z', '2024-05-17T00:00:00Z', 'M15', 'EUR_USD')\n",
    "# print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "# Function to plot candlestick chart with response text\n",
    "def plot_candlestick_chart(df, filename, response_text=None):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index.name = 'Date'\n",
    "    mc = mpf.make_marketcolors(up='green', down='red', wick={'up':'green', 'down':'red'}, edge={'up':'green', 'down':'red'})\n",
    "    s = mpf.make_mpf_style(marketcolors=mc, gridstyle='--')\n",
    "    addplots = []\n",
    "    if 'SMA20' in df.columns:\n",
    "        addplots.append(mpf.make_addplot(df['SMA20'], color='blue'))\n",
    "    if 'SMA50' in df.columns:\n",
    "        addplots.append(mpf.make_addplot(df['SMA50'], color='orange'))\n",
    "    fig, axlist = mpf.plot(df, type='candle', style=s, addplot=addplots, volume=True, returnfig=True)\n",
    "    if response_text:\n",
    "        axlist[0].text(0.5, -0.3, response_text, transform=axlist[0].transAxes, fontsize=8, verticalalignment='bottom', horizontalalignment='center', bbox=dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "    fig.savefig(filename)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image to base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Analyze image with GPT-4o\n",
    "def analyze_image_with_gpt4o(filename, chart_count, pair, timeframe, window_data):\n",
    "    base64_image = encode_image(filename)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "    prompt = (\n",
    "        \"Please check this image pattern and give me the list of patterns for EUR/USD 5-minute chart on this chart. \"\n",
    "        \"Provide the pattern detection results in JSON format, including the following details:\\n\"\n",
    "        \"- id\\n\"\n",
    "        \"- pattern_detected (0 for no pattern, 1 for one pattern, 2 for two patterns, 3 for three patterns, etc.)\\n\"\n",
    "        \"- pattern name\\n\"\n",
    "        \"- pattern type\\n\"\n",
    "        \"- confidence percentage (from 1 to 100)\\n\"\n",
    "        \"- entry point for trade\\n\"\n",
    "        \"- take profit\\n\"\n",
    "        \"- stop loss\\n\"\n",
    "        \"- best time for exiting order if take profit or stop loss is not achieved\\n\"\n",
    "        \"- order id\\n\"\n",
    "        \"- input data (pairs, timeframe, image name)\\n\"\n",
    "        \"- description (any additional notes or ideas not covered by the other fields)\\n\\n\"\n",
    "        \"If no patterns are detected, include an empty JSON array with 'pattern_detected' set to 0.\\n\\n\"\n",
    "        \"Please note: I do not intend to use this data for trading or any other financial work. Please just double check the chart and provide the correct answer.\\n\\n\"\n",
    "        \"Don't send any description, text, or other response rather than JSON format\\n\\n\"\n",
    "        \"Here is an example of the JSON format:\\n\\n\"\n",
    "        \"[\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"        \\\"id\\\": 1,\\n\"\n",
    "        \"        \\\"pattern_detected\\\": 1,\\n\"\n",
    "        \"        \\\"pattern_name\\\": \\\"Double Top\\\",\\n\"\n",
    "        \"        \\\"pattern_type\\\": \\\"Reversal\\\",\\n\"\n",
    "        \"        \\\"confidence_percentage\\\": 90,\\n\"\n",
    "        \"        \\\"entry_point\\\": \\\"2024-01-12T06:00:00Z\\\",\\n\"\n",
    "        \"        \\\"take_profit\\\": 1.0800,\\n\"\n",
    "        \"        \\\"stop_loss\\\": 1.0950,\\n\"\n",
    "        \"        \\\"best_exit_time\\\": \\\"2024-01-13T06:00:00Z\\\",\\n\"\n",
    "        \"        \\\"order_id\\\": \\\"ORD123456\\\",\\n\"\n",
    "        \"        \\\"input_data\\\": {\\n\"\n",
    "        \"            \\\"pairs\\\": \\\"EUR/USD\\\",\\n\"\n",
    "        \"            \\\"timeframe\\\": \\\"5 minutes\\\",\\n\"\n",
    "        \"            \\\"image_name\\\": \\\"image1.png\\\"\\n\"\n",
    "        \"        },\\n\"\n",
    "        \"        \\\"description\\\": \\\"Formed after a significant upward trend.\\\"\\n\"\n",
    "        \"    },\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"        \\\"id\\\": 2,\\n\"\n",
    "        \"        \\\"pattern_detected\\\": 2,\\n\"\n",
    "        \"        \\\"pattern_name\\\": \\\"Head and Shoulders\\\",\\n\"\n",
    "        \"        \\\"pattern_type\\\": \\\"Reversal\\\",\\n\"\n",
    "        \"        \\\"confidence_percentage\\\": 85,\\n\"\n",
    "        \"        \\\"entry_point\\\": \\\"2024-01-10T04:00:00Z\\\",\\n\"\n",
    "        \"        \\\"take_profit\\\": 1.0750,\\n\"\n",
    "        \"        \\\"stop_loss\\\": 1.0900,\\n\"\n",
    "        \"        \\\"best_exit_time\\\": \\\"2024-01-11T04:00:00Z\\\",\\n\"\n",
    "        \"        \\\"order_id\\\": \\\"ORD123457\\\",\\n\"\n",
    "        \"        \\\"input_data\\\": {\\n\"\n",
    "        \"            \\\"pairs\\\": \\\"EUR/USD\\\",\\n\"\n",
    "        \"            \\\"timeframe\\\": \\\"5 minutes\\\",\\n\"\n",
    "        \"            \\\"image_name\\\": \\\"image2.png\\\"\\n\"\n",
    "        \"        },\\n\"\n",
    "        \"        \\\"description\\\": \\\"Indicates a possible reversal of the current trend.\\\"\\n\"\n",
    "        \"    }\\n\"\n",
    "        \"]\\n\"\n",
    "        \"If no patterns are detected:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"        \\\"id\\\": 1,\\n\"\n",
    "        \"        \\\"pattern_detected\\\": 0\\n\"\n",
    "        \"    }\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    pattern_data = response.json()\n",
    "    pattern_data['id'] = chart_count\n",
    "    pattern_data['pair'] = pair\n",
    "    pattern_data['timeframe'] = timeframe\n",
    "    if 'input_data' not in pattern_data:\n",
    "        pattern_data['input_data'] = {}\n",
    "    pattern_data['input_data']['pairs'] = pair\n",
    "    pattern_data['input_data']['timeframe'] = timeframe\n",
    "    pattern_data['input_data']['image_name'] = filename\n",
    "    return pattern_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place an order\n",
    "def place_order(pattern):\n",
    "    order_details = {\n",
    "        'id': pattern['id'],\n",
    "        'pattern_name': pattern['pattern_name'],\n",
    "        'pattern_type': pattern['pattern_type'],\n",
    "        'confidence_percentage': pattern['confidence_percentage'],\n",
    "        'entry_point': pattern['entry_point'],\n",
    "        'take_profit': pattern['take_profit'],\n",
    "        'stop_loss': pattern['stop_loss'],\n",
    "        'best_exit_time': pattern['best_exit_time'],\n",
    "        'order_id': pattern['order_id']\n",
    "    }\n",
    "    with open('orders_log.json', 'a') as log_file:\n",
    "        json.dump(order_details, log_file, indent=4)\n",
    "        log_file.write('\\n')\n",
    "    print(f\"Placing order: {order_details}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_moving_window_charts(prices, window_size, step_size, base_dir):\n",
    "    start_index = 0\n",
    "    end_index = window_size\n",
    "    chart_count = 0\n",
    "    results = []\n",
    "\n",
    "    while start_index < len(prices):\n",
    "        window_data = prices.iloc[start_index:end_index].copy()\n",
    "        if window_data.empty:\n",
    "            break\n",
    "        # Ensure the index is datetime\n",
    "        window_data.index = pd.to_datetime(window_data.index)\n",
    "        year = window_data.index[0].year\n",
    "        year_dir = os.path.join(base_dir, str(year))\n",
    "        os.makedirs(year_dir, exist_ok=True)\n",
    "        start_date = window_data.index[0].strftime('%Y-%m-%d_%H-%M')\n",
    "        end_date = window_data.index[-1].strftime('%Y-%m-%d_%H-%M')\n",
    "        filename = os.path.join(year_dir, f'{start_date}_to_{end_date}.png')\n",
    "        plot_candlestick_chart(window_data, filename)\n",
    "        logging.info(f'Created chart image: {filename}')\n",
    "        result = analyze_image_with_gpt4o(filename, chart_count, pair, timeframe, window_data)\n",
    "        results.append(result)\n",
    "        start_index += step_size\n",
    "        end_index = start_index + window_size\n",
    "        chart_count += 1\n",
    "\n",
    "    with open('pattern_detection_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_forex_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(base_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Run the real-time data fetching and processing\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43mfetch_and_process_realtime_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgranularity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstrument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m, in \u001b[0;36mfetch_and_process_realtime_data\u001b[1;34m(granularity, instrument, pair, timeframe, base_dir, window_size, step_size)\u001b[0m\n\u001b[0;32m     10\u001b[0m start_time \u001b[38;5;241m=\u001b[39m (datetime\u001b[38;5;241m.\u001b[39mnow(timezone\u001b[38;5;241m.\u001b[39mutc) \u001b[38;5;241m-\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mSZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching initial data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m initial_prices \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_forex_data\u001b[49m(start_time, end_time, granularity, instrument)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_prices\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     16\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo initial data fetched. Exiting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fetch_forex_data' is not defined"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# Ensure all your imports and configurations are correct, including the fetch_forex_data function\n",
    "\n",
    "\n",
    "def fetch_and_process_realtime_data(granularity, instrument, pair, timeframe, base_dir, window_size, step_size):\n",
    "    end_time = (datetime.now(timezone.utc) - timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    start_time = (datetime.now(timezone.utc) - timedelta(days=4)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    logging.info(f\"Fetching initial data from {start_time} to {end_time}\")\n",
    "    initial_prices = fetch_forex_data(start_time, end_time, granularity, instrument)\n",
    "\n",
    "    if initial_prices.empty:\n",
    "        logging.error(\"No initial data fetched. Exiting.\")\n",
    "        return\n",
    "\n",
    "    create_moving_window_charts(initial_prices, 1000, step_size, base_dir)\n",
    "\n",
    "    while True:\n",
    "        end_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        start_time = (datetime.now(timezone.utc) - timedelta(minutes=5 * 576 / 12)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        logging.info(f\"Fetching data from {start_time} to {end_time}\")\n",
    "        prices = fetch_forex_data(start_time, end_time, granularity, instrument)\n",
    "        \n",
    "        if prices.empty:\n",
    "            logging.error(\"No data fetched. Retrying in 5 minutes.\")\n",
    "        else:\n",
    "            create_moving_window_charts(prices, window_size, step_size, base_dir)\n",
    "        \n",
    "        logging.info(\"Sleeping for 5 minutes before fetching new data\")\n",
    "        time.sleep(300)\n",
    "\n",
    "\n",
    "# Set the parameters for real-time data fetching and processing\n",
    "granularity = 'M5'\n",
    "instrument = 'EUR_USD'\n",
    "pair = 'EUR_USD'\n",
    "timeframe = '5 minutes'\n",
    "base_dir = f'{pair}/{timeframe}'\n",
    "window_size = 576  # Adjust window size for detecting single patterns\n",
    "step_size = 5      # Adjust step size accordingly\n",
    "\n",
    "# Create base directory if it does not exist\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Run the real-time data fetching and processing\n",
    "fetch_and_process_realtime_data(granularity, instrument, pair, timeframe, base_dir, window_size, step_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
