{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Historical Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v20\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.contrib.factories import InstrumentsCandlesFactory\n",
    "import os\n",
    "import mplfinance as mpf\n",
    "import openai\n",
    "import base64\n",
    "import requests\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OANDA API configuration using environment variables\n",
    "api = v20.Context(\n",
    "    hostname='api-fxpractice.oanda.com',\n",
    "    port=443,\n",
    "    ssl=True,\n",
    "    token=os.getenv('OANDA_API_TOKEN'),\n",
    "    datetime_format='RFC3339'\n",
    ")\n",
    "access_token = os.getenv('OANDA_API_TOKEN')\n",
    "\n",
    "# Set OpenAI API key from environment variables\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Fetch Historical Data\n",
    "def fetch_forex_data(from_date, to_date, granularity, instrument):\n",
    "    client = API(access_token=access_token, environment=\"practice\")\n",
    "    params = {\n",
    "        \"granularity\": granularity,\n",
    "        \"from\": from_date,\n",
    "        \"to\": to_date\n",
    "    }\n",
    "    data = []\n",
    "    try:\n",
    "        for request in InstrumentsCandlesFactory(instrument=instrument, params=params):\n",
    "            response = client.request(request)\n",
    "            if response:\n",
    "                for candle in response.get('candles'):\n",
    "                    rec = {\n",
    "                        'time': candle.get('time')[0:19],\n",
    "                        'complete': candle['complete'],\n",
    "                        'open': float(candle['mid']['o']),\n",
    "                        'high': float(candle['mid']['h']),\n",
    "                        'low': float(candle['mid']['l']),\n",
    "                        'close': float(candle['mid']['c']),\n",
    "                        'volume': candle['volume'],\n",
    "                    }\n",
    "                    data.append(rec)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred fetching data: {e}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "prices = fetch_forex_data('2016-01-01T00:00:00Z', '2016-04-18T00:00:00Z', 'M15', 'EUR_USD')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Moving Average Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Moving Average Strategy\n",
    "def simple_moving_average_strategy(df):\n",
    "    df['SMA20'] = df['close'].rolling(window=20).mean()\n",
    "    df['SMA50'] = df['close'].rolling(window=50).mean()\n",
    "    df['signal'] = 0\n",
    "    df.loc[50:, 'signal'] = np.where(df['SMA20'][50:] > df['SMA50'][50:], 1, 0)\n",
    "    df['position'] = df['signal'].diff()\n",
    "    return df\n",
    "\n",
    "df = simple_moving_average_strategy(prices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Prices and Create Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'time' column is in datetime format\n",
    "# prices['time'] = pd.to_datetime(prices['time'])\n",
    "\n",
    "# Set 'time' column as the index\n",
    "prices.set_index('time', inplace=True)\n",
    "\n",
    "# Define window size and step size\n",
    "window_size = 50  # Adjust window size for detecting single patterns\n",
    "step_size = 10    # Adjust step size accordingly\n",
    "\n",
    "# Create directories based on forex pair, timeframe, and year\n",
    "pair = 'EUR_USD'\n",
    "timeframe = 'M15'\n",
    "base_dir = f'{pair}/{timeframe}'\n",
    "\n",
    "# Create base directory if it does not exist\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Plot candlestick chart\n",
    "def plot_candlestick_chart(df, filename):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index.name = 'Date'\n",
    "    mc = mpf.make_marketcolors(up='green', down='red', wick={'up':'green', 'down':'red'}, edge={'up':'green', 'down':'red'})\n",
    "    s = mpf.make_mpf_style(marketcolors=mc, gridstyle='--')\n",
    "    addplots = []\n",
    "    if 'SMA20' in df.columns:\n",
    "        addplots.append(mpf.make_addplot(df['SMA20'], color='blue'))\n",
    "    if 'SMA50' in df.columns:\n",
    "        addplots.append(mpf.make_addplot(df['SMA50'], color='orange'))\n",
    "    mpf.plot(df, type='candle', style=s, addplot=addplots, volume=True, savefig=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Image with GPT-4o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image to base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Analyze image with GPT-4o\n",
    "def analyze_image_with_gpt4o(filename, chart_count, pair, timeframe, window_data):\n",
    "    base64_image = encode_image(filename)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "    prompt = (\n",
    "        \"Please check this image pattern and give me the list of patterns for EUR/USD 15-minute chart on this chart. \"\n",
    "        \"Provide the pattern detection results in JSON format, including the following details:\\n\"\n",
    "        \"- id\\n\"\n",
    "        \"- pattern_detected (0 for no pattern, 1 for one pattern, 2 for two patterns, 3 for three patterns, etc.)\\n\"\n",
    "        \"- pattern name\\n\"\n",
    "        \"- pattern type\\n\"\n",
    "        \"- confidence percentage (from 1 to 100)\\n\"\n",
    "        \"- entry point for trade\\n\"\n",
    "        \"- take profit\\n\"\n",
    "        \"- stop loss\\n\"\n",
    "        \"- best time for exiting order if take profit or stop loss is not achieved\\n\"\n",
    "        \"- order id\\n\"\n",
    "        \"- input data (pairs, timeframe, image name)\\n\"\n",
    "        \"- description (any additional notes or ideas not covered by the other fields)\\n\\n\"\n",
    "        \"If no patterns are detected, include an empty JSON array with 'pattern_detected' set to 0.\\n\\n\"\n",
    "        \"Please note: I do not intend to use this data for trading or any other financial work. Please just double check the chart and provide the correct answer.\\n\\n\"\n",
    "        \"Don't send any description, text, or other response rather than JSON format\\n\\n\"\n",
    "        \"Here is an example of the JSON format:\\n\\n\"\n",
    "        \"[\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"        \\\"id\\\": 1,\\n\"\n",
    "        \"        \\\"pattern_detected\\\": 1,\\n\"\n",
    "        \"        \\\"pattern_name\\\": \\\"Double Top\\\",\\n\"\n",
    "        \"        \\\"pattern_type\\\": \\\"Reversal\\\",\\n\"\n",
    "        \"        \\\"confidence_percentage\\\": 90,\\n\"\n",
    "        \"        \\\"entry_point\\\": \\\"2024-01-12T06:00:00Z\\\",\\n\"\n",
    "        \"        \\\"take_profit\\\": 1.0800,\\n\"\n",
    "        \"        \\\"stop_loss\\\": 1.0950,\\n\"\n",
    "        \"        \\\"best_exit_time\\\": \\\"2024-01-13T06:00:00Z\\\",\\n\"\n",
    "        \"        \\\"order_id\\\": \\\"ORD123456\\\",\\n\"\n",
    "        \"        \\\"input_data\\\": {\\n\"\n",
    "        \"            \\\"pairs\\\": \\\"EUR/USD\\\",\\n\"\n",
    "        \"            \\\"timeframe\\\": \\\"15 minutes\\\",\\n\"\n",
    "        \"            \\\"image_name\\\": \\\"image1.png\\\"\\n\"\n",
    "        \"        },\\n\"\n",
    "        \"        \\\"description\\\": \\\"Formed after a significant upward trend.\\\"\\n\"\n",
    "        \"    },\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"        \\\"id\\\": 2,\\n\"\n",
    "        \"        \\\"pattern_detected\\\": 2,\\n\"\n",
    "        \"        \\\"pattern_name\\\": \\\"Head and Shoulders\\\",\\n\"\n",
    "        \"        \\\"pattern_type\\\": \\\"Reversal\\\",\\n\"\n",
    "        \"        \\\"confidence_percentage\\\": 85,\\n\"\n",
    "        \"        \\\"entry_point\\\": \\\"2024-01-10T04:00:00Z\\\",\\n\"\n",
    "        \"        \\\"take_profit\\\": 1.0750,\\n\"\n",
    "        \"        \\\"stop_loss\\\": 1.0900,\\n\"\n",
    "        \"        \\\"best_exit_time\\\": \\\"2024-01-11T04:00:00Z\\\",\\n\"\n",
    "        \"        \\\"order_id\\\": \\\"ORD123457\\\",\\n\"\n",
    "        \"        \\\"input_data\\\": {\\n\"\n",
    "        \"            \\\"pairs\\\": \\\"EUR/USD\\\",\\n\"\n",
    "        \"            \\\"timeframe\\\": \\\"15 minutes\\\",\\n\"\n",
    "        \"            \\\"image_name\\\": \\\"image2.png\\\"\\n\"\n",
    "        \"        },\\n\"\n",
    "        \"        \\\"description\\\": \\\"Indicates a possible reversal of the current trend.\\\"\\n\"\n",
    "        \"    }\\n\"\n",
    "        \"]\\n\"\n",
    "        \"If no patterns are detected:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"        \\\"id\\\": 1,\\n\"\n",
    "        \"        \\\"pattern_detected\\\": 0\\n\"\n",
    "        \"    }\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    pattern_data = response.json()\n",
    "    pattern_data['id'] = chart_count\n",
    "    pattern_data['pair'] = pair\n",
    "    pattern_data['timeframe'] = timeframe\n",
    "    if 'input_data' not in pattern_data:\n",
    "        pattern_data['input_data'] = {}\n",
    "    pattern_data['input_data']['pairs'] = pair\n",
    "    pattern_data['input_data']['timeframe'] = timeframe\n",
    "    pattern_data['input_data']['image_name'] = filename\n",
    "    return pattern_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Place Order Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to place an order\n",
    "def place_order(pattern):\n",
    "    if pattern.get('confidence_percentage', 0) > 50:\n",
    "        order_details = {\n",
    "            \"instrument\": pattern['pair'],\n",
    "            \"units\": 1000,  # example size\n",
    "            \"type\": \"market\",\n",
    "            \"side\": \"buy\" if pattern['pattern_type'] == \"Continuation\" else \"sell\",\n",
    "            \"take_profit\": pattern['take_profit'],\n",
    "            \"stop_loss\": pattern['stop_loss'],\n",
    "            \"entry_point\": pattern['entry_point']\n",
    "        }\n",
    "        # Log order details\n",
    "        with open('orders_log.json', 'a') as log_file:\n",
    "            json.dump(order_details, log_file, indent=4)\n",
    "            log_file.write('\\n')\n",
    "        print(f\"Placing order: {order_details}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Analyze Moving Window Charts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create moving window charts and analyze with GPT-4o\n",
    "def create_moving_window_charts(prices, window_size, step_size, base_dir):\n",
    "    start_index = 0\n",
    "    end_index = window_size\n",
    "    chart_count = 0\n",
    "    results = []\n",
    "\n",
    "    while start_index < len(prices):\n",
    "        window_data = prices.iloc[start_index:end_index].copy()\n",
    "        year = window_data.index[0].year\n",
    "        year_dir = os.path.join(base_dir, str(year))\n",
    "        os.makedirs(year_dir, exist_ok=True)\n",
    "        start_date = window_data.index[0].strftime('%Y-%m-%d_%H-%M')\n",
    "        end_date = window_data.index[-1].strftime('%Y-%m-%d_%H-%M')\n",
    "        filename = os.path.join(year_dir, f'{start_date}_to_{end_date}.png')\n",
    "        plot_candlestick_chart(window_data, filename)\n",
    "        print(f'Created chart image: {filename}')\n",
    "        result = analyze_image_with_gpt4o(filename, chart_count, pair, timeframe, window_data)\n",
    "        results.append(result)\n",
    "        if 'choices' in result:\n",
    "            for choice in result['choices']:\n",
    "                try:\n",
    "                    message_content = json.loads(choice['message']['content'])\n",
    "                    for pattern in message_content:\n",
    "                        if pattern.get('confidence_percentage', 0) > 50:\n",
    "                            place_order(pattern)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"JSON decode error: {e}\")\n",
    "        start_index += step_size\n",
    "        end_index = start_index + window_size\n",
    "        chart_count += 1\n",
    "\n",
    "    with open('pattern_detection_results.json', 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32md:\\OneDrive\\myproject\\chatgpt-trader\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure 'time' column is in datetime format\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mprices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Set 'time' column as the index\u001b[39;00m\n\u001b[0;32m      6\u001b[0m prices\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\OneDrive\\myproject\\chatgpt-trader\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32md:\\OneDrive\\myproject\\chatgpt-trader\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "# Ensure 'time' column is in datetime format\n",
    "# \n",
    "prices['time'] = pd.to_datetime(prices['time'])\n",
    "\n",
    "# Set 'time' column as the index\n",
    "prices.set_index('time', inplace=True)\n",
    "\n",
    "# Define window size and step size for small window size\n",
    "window_size = 50  # Adjust window size for detecting single patterns\n",
    "step_size = 10    # Adjust step size accordingly\n",
    "\n",
    "# Create directories based on forex pair, timeframe, and year\n",
    "pair = 'EUR_USD'\n",
    "timeframe = 'M15'\n",
    "base_dir = f'{pair}/{timeframe}'\n",
    "\n",
    "# Create base directory if it does not exist\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "# Create and analyze moving window charts\n",
    "create_moving_window_charts(prices, window_size, step_size, base_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
