{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take order using image and data using openai api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fetching forex data from 2024-06-06T03:12:49Z to 2024-06-08T03:12:49Z with granularity M15 for instrument EUR_USD\n",
      "INFO:root:Data sent: 2199 tokens, Cost: $0.010995, Image Cost: $0.085000\n",
      "INFO:root:Sending data to OpenAI API for analysis\n",
      "INFO:root:OpenAI API Analysis Result: {\n",
      "    \"id\": \"chatcmpl-9XgneqRmi4wmmzxzOQXw6Yt8H4V9z\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1717816374,\n",
      "    \"model\": \"gpt-4o-2024-05-13\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"```json\\n{\\n    \\\"orders\\\": [\\n        {\\n            \\\"timeframe\\\": \\\"15 minutes\\\",\\n            \\\"pattern_name\\\": \\\"Bollinger Bands Narrowing\\\",\\n            \\\"confidence_percentage\\\": 85,\\n            \\\"action\\\": \\\"Buy\\\",\\n            \\\"entry_price\\\": 1.08784,\\n            \\\"take_profit\\\": 1.09050,\\n            \\\"stop_loss\\\": 1.08700,\\n            \\\"profit_loss_ratio\\\": 3.0,\\n            \\\"deadline_date\\\": \\\"2023-10-10T15:45:00Z\\\"\\n        },\\n        {\\n            \\\"timeframe\\\": \\\"30 minutes\\\",\\n            \\\"pattern_name\\\": \\\"RSI Oversold\\\",\\n            \\\"confidence_percentage\\\": 90,\\n            \\\"action\\\": \\\"Buy\\\",\\n            \\\"entry_price\\\": 1.08251,\\n            \\\"take_profit\\\": 1.08500,\\n            \\\"stop_loss\\\": 1.08050,\\n            \\\"profit_loss_ratio\\\": 2.5,\\n            \\\"deadline_date\\\": \\\"2023-10-10T16:30:00Z\\\"\\n        }\\n    ],\\n    \\\"best_pattern\\\": {\\n        \\\"pattern_name\\\": \\\"RSI Oversold\\\",\\n        \\\"confidence_percentage\\\": 90,\\n        \\\"action\\\": \\\"Buy\\\",\\n        \\\"entry_price\\\": 1.08251,\\n        \\\"take_profit\\\": 1.08500,\\n        \\\"stop_loss\\\": 1.08050,\\n        \\\"profit_loss_ratio\\\": 2.5,\\n        \\\"deadline_date\\\": \\\"2023-10-10T16:30:00Z\\\"\\n    }\\n}\\n```\"\n",
      "            },\n",
      "            \"logprobs\": null,\n",
      "            \"finish_reason\": \"stop\"\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 37663,\n",
      "        \"completion_tokens\": 319,\n",
      "        \"total_tokens\": 37982\n",
      "    },\n",
      "    \"system_fingerprint\": \"fp_319be4768e\"\n",
      "}\n",
      "INFO:root:Response received: 319 tokens, Cost: $0.004785\n",
      "INFO:root:Order Details - Action: Buy, Entry Price: 1.08784, Take Profit: 1.0905, Stop Loss: 1.087\n",
      "INFO:root:Order placed successfully: {'orderCreateTransaction': {'id': '125', 'accountID': '101-002-7656987-005', 'userID': 7656987, 'batchID': '125', 'requestID': '115291435193556722', 'time': '2024-06-08T03:13:05.844736334Z', 'type': 'MARKET_ORDER', 'instrument': 'EUR_USD', 'units': '10000', 'timeInForce': 'FOK', 'positionFill': 'DEFAULT', 'takeProfitOnFill': {'price': '1.09050', 'timeInForce': 'GTC'}, 'stopLossOnFill': {'price': '1.08700', 'timeInForce': 'GTC', 'triggerMode': 'TOP_OF_BOOK'}, 'reason': 'CLIENT_ORDER'}, 'orderCancelTransaction': {'id': '126', 'accountID': '101-002-7656987-005', 'userID': 7656987, 'batchID': '125', 'requestID': '115291435193556722', 'time': '2024-06-08T03:13:05.844736334Z', 'type': 'ORDER_CANCEL', 'orderID': '125', 'reason': 'MARKET_HALTED'}, 'relatedTransactionIDs': ['125', '126'], 'lastTransactionID': '126'}\n",
      "INFO:root:Order 125 was canceled: MARKET_HALTED\n",
      "INFO:root:Order placed based on analysis.\n",
      "INFO:root:Total cost for this run: Data: $0.010995, Image: $0.051166, Response: $0.004785, Total: $0.066946\n",
      "INFO:root:Waiting for 15 minutes before next run...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import v20\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "from oandapyV20 import API\n",
    "from oandapyV20.contrib.factories import InstrumentsCandlesFactory\n",
    "from oandapyV20.contrib.requests import MarketOrderRequest, TakeProfitDetails, StopLossDetails\n",
    "from oandapyV20.endpoints.orders import OrderCreate\n",
    "from oandapyV20.exceptions import V20Error\n",
    "import openai\n",
    "import mplfinance as mpf\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import time\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# OANDA API configuration\n",
    "access_token = os.getenv('OANDA_API_TOKEN')\n",
    "account_id = os.getenv('OANDA_ACCOUNT_ID')\n",
    "api = API(access_token=access_token, environment=\"practice\")\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"oandapyV20\").setLevel(logging.WARNING)\n",
    "\n",
    "# Parameters for real-time data fetching and processing\n",
    "granularity = 'M15'  # Updated granularity to 15 minutes\n",
    "instrument = 'EUR_USD'\n",
    "pair = 'EUR_USD'\n",
    "timeframe = '15 minutes'\n",
    "window_size = 576  # Adjust window size for detecting single patterns\n",
    "step_size = 5      # Adjust step size accordingly\n",
    "\n",
    "def fetch_forex_data(from_date, to_date, granularity, instrument):\n",
    "    logging.info(f\"Fetching forex data from {from_date} to {to_date} with granularity {granularity} for instrument {instrument}\")\n",
    "    params = {\n",
    "        \"granularity\": granularity,\n",
    "        \"from\": from_date,\n",
    "        \"to\": to_date\n",
    "    }\n",
    "    data = []\n",
    "    try:\n",
    "        for request in InstrumentsCandlesFactory(instrument=instrument, params=params):\n",
    "            response = api.request(request)\n",
    "            if response:\n",
    "                for candle in response.get('candles'):\n",
    "                    rec = {\n",
    "                        'time': candle.get('time')[0:19],\n",
    "                        'complete': candle['complete'],\n",
    "                        'open': float(candle['mid']['o']),\n",
    "                        'high': float(candle['mid']['h']),\n",
    "                        'low': float(candle['mid']['l']),\n",
    "                        'close': float(candle['mid']['c']),\n",
    "                        'volume': candle['volume'],\n",
    "                    }\n",
    "                    data.append(rec)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred fetching data: {e}\")\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def calculate_rsi(data, length=14):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=length).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=length).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(data, fast_period=12, slow_period=26, signal_period=9):\n",
    "    fast_ema = data.ewm(span=fast_period, adjust=False).mean()\n",
    "    slow_ema = data.ewm(span=slow_period, adjust=False).mean()\n",
    "    macd = fast_ema - slow_ema\n",
    "    signal = macd.ewm(span=signal_period, adjust=False).mean()\n",
    "    return macd, signal\n",
    "\n",
    "def calculate_bollinger_bands(data, window=20, no_of_std=2):\n",
    "    rolling_mean = data.rolling(window).mean()\n",
    "    rolling_std = data.rolling(window).std()\n",
    "    upper_band = rolling_mean + (rolling_std * no_of_std)\n",
    "    lower_band = rolling_mean - (rolling_std * no_of_std)\n",
    "    return rolling_mean, upper_band, lower_band\n",
    "\n",
    "def calculate_fibonacci_retracement(data):\n",
    "    max_price = data['high'].max()\n",
    "    min_price = data['low'].min()\n",
    "    diff = max_price - min_price\n",
    "    levels = [max_price - diff * r for r in [0.236, 0.382, 0.5, 0.618, 0.786]]\n",
    "    return levels\n",
    "\n",
    "def calculate_ichimoku(data):\n",
    "    high_9 = data['high'].rolling(window=9).max()\n",
    "    low_9 = data['low'].rolling(window=9).min()\n",
    "    high_26 = data['high'].rolling(window=26).max()\n",
    "    low_26 = data['low'].rolling(window=26).min()\n",
    "    high_52 = data['high'].rolling(window=52).max()\n",
    "    low_52 = data['low'].rolling(window=52).min()\n",
    "    \n",
    "    tenkan_sen = (high_9 + low_9) / 2\n",
    "    kijun_sen = (high_26 + low_26) / 2\n",
    "    senkou_span_a = ((tenkan_sen + kijun_sen) / 2).shift(26)\n",
    "    senkou_span_b = ((high_52 + low_52) / 2).shift(26)\n",
    "    chikou_span = data['close'].shift(-26)\n",
    "    \n",
    "    return tenkan_sen, kijun_sen, senkou_span_a, senkou_span_b, chikou_span\n",
    "\n",
    "def plot_candlestick_chart(df, filename):\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index.name = 'Date'\n",
    "    df['SMA20'] = df['close'].rolling(window=20).mean()\n",
    "    df['SMA50'] = df['close'].rolling(window=50).mean()\n",
    "    mc = mpf.make_marketcolors(up='green', down='red', wick={'up':'green', 'down':'red'}, edge={'up':'green', 'down':'red'})\n",
    "    s = mpf.make_mpf_style(marketcolors=mc, gridstyle='--')\n",
    "    addplots = [mpf.make_addplot(df['SMA20'], color='blue'), mpf.make_addplot(df['SMA50'], color='orange')]\n",
    "    mpf.plot(df, type='candle', style=s, addplot=addplots, volume=True, savefig=filename)\n",
    "\n",
    "def compress_image(input_path, output_path, quality=85):\n",
    "    with Image.open(input_path) as img:\n",
    "        img = img.convert('RGB')  # Convert to RGB\n",
    "        img = img.resize((500, 300), Image.LANCZOS)  # Resize to 500x300\n",
    "        img.save(output_path, 'JPEG', quality=quality)  # Save with reduced quality\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def analyze_data_with_gpt4o(indicators_summary, image_base64):\n",
    "    logging.info(\"Sending data to OpenAI API for analysis\")\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "    \n",
    "    prompt_content = {\n",
    "        \"content\": \"Analyze the indicators data for EUR/USD and provide order details with profit/loss greater than 2. Combine all patterns found and aggregate them to find the best pattern with the highest probability, most profit/loss, and strongest win signs. The patterns should not be in the past and should happen now or in the near future. Dont send any descriotions or extra text.\\n\\n\"\n",
    "                   \"Provide the analysis in JSON format with the following structure:\\n\\n\"\n",
    "                   \"{\\n\"\n",
    "                   \"    \\\"orders\\\": [\\n\"\n",
    "                   \"        {\\n\"\n",
    "                   \"            \\\"timeframe\\\": \\\"# minutes\\\",\\n\"\n",
    "                   \"            \\\"pattern_name\\\": \\\"Pattern Name\\\",\\n\"\n",
    "                   \"            \\\"confidence_percentage\\\": ##,\\n\"\n",
    "                   \"            \\\"action\\\": \\\"####\\\",\\n\"\n",
    "                   \"            \\\"entry_price\\\": #.####,\\n\"\n",
    "                   \"            \\\"take_profit\\\": #.####,\\n\"\n",
    "                   \"            \\\"stop_loss\\\": #.####,\\n\"\n",
    "                   \"            \\\"profit_loss_ratio\\\": ##,\\n\"\n",
    "                   \"            \\\"deadline_date\\\": \\\"####-##-##T##:##:##Z\\\"\\n\"\n",
    "                   \"        }\\n\"\n",
    "                   \"    ],\\n\"\n",
    "                   \"    \\\"best_pattern\\\": {\\n\"\n",
    "                   \"        \\\"pattern_name\\\": \\\"Pattern Name\\\",\\n\"\n",
    "                   \"        \\\"confidence_percentage\\\": ##,\\n\"\n",
    "                   \"        \\\"action\\\": \\\"####\\\",\\n\"\n",
    "                   \"        \\\"entry_price\\\": #.####,\\n\"\n",
    "                   \"            \\\"take_profit\\\": #.####,\\n\"\n",
    "                   \"            \\\"stop_loss\\\": #.####,\\n\"\n",
    "                   \"            \\\"profit_loss_ratio\\\": ##,\\n\"\n",
    "                   \"            \\\"deadline_date\\\": \\\"####-##-##T##:##:##Z\\\"\\n\"\n",
    "                   \"    }\\n\"\n",
    "                   \"}\\n\",\n",
    "        \"image\": f\"data:image/png;base64,{image_base64}\",\n",
    "        \"indicators_summary\": indicators_summary\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": json.dumps(prompt_content)\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 3000\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    try:\n",
    "        response_data = response.json()\n",
    "        return response_data\n",
    "    except json.JSONDecodeError:\n",
    "        logging.error(\"Failed to decode JSON response from OpenAI API\")\n",
    "        return None\n",
    "\n",
    "def extract_and_place_order(response_data):\n",
    "    if not response_data or \"choices\" not in response_data:\n",
    "        logging.error(\"Invalid response data\")\n",
    "        return None\n",
    "\n",
    "    content = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    start_index = content.find('{')\n",
    "    end_index = content.rfind('}') + 1\n",
    "    json_content = content[start_index:end_index]\n",
    "    \n",
    "    try:\n",
    "        analysis = json.loads(json_content)\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Failed to parse JSON content: {e}\")\n",
    "        return None\n",
    "    \n",
    "    orders = analysis.get(\"orders\", [])\n",
    "    best_pattern = analysis.get(\"best_pattern\", {})\n",
    "    \n",
    "    for order in orders:\n",
    "        if order.get(\"profit_loss_ratio\", 0) > 2:\n",
    "            logging.info(f\"Order Details - Action: {order['action']}, Entry Price: {order['entry_price']}, Take Profit: {order['take_profit']}, Stop Loss: {order['stop_loss']}\")\n",
    "            \n",
    "            order_details = {\n",
    "                'action': order['action'],\n",
    "                'entry_price': order['entry_price'],\n",
    "                'take_profit': order['take_profit'],\n",
    "                'stop_loss': order['stop_loss'],\n",
    "                'deadline_date': order['deadline_date']\n",
    "            }\n",
    "            response = place_order(order_details)\n",
    "            \n",
    "            if 'orderCancelTransaction' in response:\n",
    "                logging.info(f\"Order {response['orderCancelTransaction']['orderID']} was canceled: {response['orderCancelTransaction']['reason']}\")\n",
    "            return order_details\n",
    "\n",
    "    logging.info(f\"Best Pattern Details - Action: {best_pattern['action']}, Entry Price: {best_pattern['entry_price']}, Take Profit: {best_pattern['take_profit']}, Stop Loss: {best_pattern['stop_loss']}\")\n",
    "    return best_pattern\n",
    "\n",
    "def place_order(order_details):\n",
    "    instrument = \"EUR_USD\"\n",
    "    \n",
    "    mkt_order = MarketOrderRequest(\n",
    "        instrument=instrument,\n",
    "        units=-10000 if order_details['action'].upper() == 'SELL' else 10000,\n",
    "        takeProfitOnFill=TakeProfitDetails(price=order_details['take_profit']).data,\n",
    "        stopLossOnFill=StopLossDetails(price=order_details['stop_loss']).data\n",
    "    )\n",
    "    \n",
    "    r = OrderCreate(accountID=account_id, data=mkt_order.data)\n",
    "    try:\n",
    "        response = api.request(r)\n",
    "        logging.info(f\"Order placed successfully: {response}\")\n",
    "        return response\n",
    "    except V20Error as e:\n",
    "        logging.error(f\"Error placing order: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def calculate_cost(data, image_size_kb):\n",
    "    json_data = json.dumps(data)\n",
    "    num_tokens = len(json_data.split())\n",
    "    data_cost = num_tokens * 0.000005\n",
    "    image_cost = image_size_kb * 0.002125\n",
    "    return num_tokens, data_cost, image_cost\n",
    "\n",
    "# Main execution\n",
    "while True:\n",
    "    start_time = (datetime.now(timezone.utc) - timedelta(days=2)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    prices = fetch_forex_data(start_time, end_time, granularity, instrument)\n",
    "\n",
    "    # Calculate indicators\n",
    "    prices['RSI'] = calculate_rsi(prices['close'])\n",
    "    prices['MACD'], prices['MACD_Signal'] = calculate_macd(prices['close'])\n",
    "    prices['Bollinger_Mid'], prices['Bollinger_Upper'], prices['Bollinger_Lower'] = calculate_bollinger_bands(prices['close'])\n",
    "    prices['Fibonacci'] = pd.Series(calculate_fibonacci_retracement(prices))\n",
    "    ichimoku = calculate_ichimoku(prices)\n",
    "    prices['Tenkan_Sen'], prices['Kijun_Sen'], prices['Senkou_Span_A'], prices['Senkou_Span_B'], prices['Chikou_Span'] = ichimoku\n",
    "\n",
    "    # Collect all the data points\n",
    "    indicators_summary = {\n",
    "        \"ClosePrices\": prices['close'].to_list(),\n",
    "        \"Volume\": prices['volume'].to_list(),\n",
    "        \"RSI\": prices['RSI'].to_list(),\n",
    "        \"MACD\": prices['MACD'].to_list(),\n",
    "        \"Bollinger_Bands\": {\n",
    "            \"Middle\": prices['Bollinger_Mid'].to_list(),\n",
    "            \"Upper\": prices['Bollinger_Upper'].to_list(),\n",
    "            \"Lower\": prices['Bollinger_Lower'].to_list()\n",
    "        },\n",
    "        \"Fibonacci\": prices['Fibonacci'].to_list(),\n",
    "        \"Ichimoku\": {\n",
    "            \"Tenkan_Sen\": prices['Tenkan_Sen'].to_list(),\n",
    "            \"Kijun_Sen\": prices['Kijun_Sen'].to_list(),\n",
    "            \"Senkou_Span_A\": prices['Senkou_Span_A'].to_list(),\n",
    "            \"Senkou_Span_B\": prices['Senkou_Span_B'].to_list(),\n",
    "            \"Chikou_Span\": prices['Chikou_Span'].to_list()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    num_tokens, data_cost, image_cost = calculate_cost(indicators_summary, image_size_kb=40)  # Adjusted image size\n",
    "    logging.info(f\"Data sent: {num_tokens} tokens, Cost: ${data_cost:.6f}, Image Cost: ${image_cost:.6f}\")\n",
    "\n",
    "    # Plot and encode the image\n",
    "    filename = \"normal_chart.png\"\n",
    "    compressed_filename = \"compressed_chart.jpg\"\n",
    "    plot_candlestick_chart(prices, filename)  # Use color image\n",
    "    compress_image(filename, compressed_filename, quality=85)  # Compress without grayscale\n",
    "    image_base64 = encode_image(compressed_filename)\n",
    "    image_size_kb = len(base64.b64decode(image_base64)) / 1024\n",
    "    image_cost = image_size_kb * 0.002125  # Assuming $0.002125 per KB\n",
    "\n",
    "    analysis_result = analyze_data_with_gpt4o(indicators_summary, image_base64)\n",
    "    logging.info(f\"OpenAI API Analysis Result: {json.dumps(analysis_result, indent=4)}\")\n",
    "\n",
    "    if analysis_result:\n",
    "        response_tokens = analysis_result[\"usage\"][\"completion_tokens\"]\n",
    "        response_cost = response_tokens * 0.000015  # Adjust based on actual token cost\n",
    "        logging.info(f\"Response received: {response_tokens} tokens, Cost: ${response_cost:.6f}\")\n",
    "\n",
    "        prompt_tokens = analysis_result[\"usage\"][\"prompt_tokens\"]\n",
    "        prompt_cost = prompt_tokens * 0.00005  # Adjust based on actual token cost\n",
    "        #logging.info(f\"Prompt sent: {prompt_tokens} tokens, Cost: ${prompt_cost:.6f}\")\n",
    "\n",
    "        order_details = extract_and_place_order(analysis_result)\n",
    "    \n",
    "        if order_details:\n",
    "            logging.info(\"Order placed based on analysis.\")\n",
    "    \n",
    "    total_cost = data_cost + response_cost + image_cost\n",
    "    logging.info(f\"Total cost for this run: Data: ${data_cost:.6f}, Image: ${image_cost:.6f}, Response: ${response_cost:.6f}, Total: ${total_cost:.6f}\")\n",
    "\n",
    "    logging.info(\"Waiting for 15 minutes before next run...\")\n",
    "    time.sleep(1500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Management\n",
    "Key Considerations for Order Management\n",
    "Risk-Free Trades: After a position has moved in your favor, move the stop loss to the entry price to make the trade risk-free. This ensures you don't lose capital even if the market reverses.\n",
    "\n",
    "Dynamic Adjustments: Use your prediction models to dynamically adjust the SL and TP levels. If new patterns suggest a different direction or price target, update your orders accordingly.\n",
    "\n",
    "Multiple Orders Management: If you have multiple open positions for the same pair, ensure your order management logic can handle them efficiently, possibly by averaging entry prices and managing collective risk.\n",
    "\n",
    "Comprehensive Monitoring: Implement comprehensive monitoring of your positions, including regular checks and adjustments based on market conditions and new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def monitor_and_manage_orders(api, account_id, pair, trailing_stop_pips=10):\n",
    "    open_positions = get_open_positions(api, account_id, pair)\n",
    "    if not open_positions:\n",
    "        logging.info(f\"No open positions for {pair}\")\n",
    "        return\n",
    "\n",
    "    for position in open_positions:\n",
    "        units = position['units']\n",
    "        entry_price = float(position['price'])\n",
    "        current_price = get_current_price(api, pair)\n",
    "        logging.info(f\"Monitoring position: Entry Price: {entry_price}, Current Price: {current_price}, Units: {units}\")\n",
    "\n",
    "        # Calculate new stop loss level for trailing stop\n",
    "        if units > 0:  # Long position\n",
    "            new_stop_loss = current_price - trailing_stop_pips * 0.0001\n",
    "            if new_stop_loss > float(position['stop_loss']):\n",
    "                logging.info(f\"Updating stop loss for long position to {new_stop_loss}\")\n",
    "                update_stop_loss(api, account_id, position['id'], new_stop_loss)\n",
    "        else:  # Short position\n",
    "            new_stop_loss = current_price + trailing_stop_pips * 0.0001\n",
    "            if new_stop_loss < float(position['stop_loss']):\n",
    "                logging.info(f\"Updating stop loss for short position to {new_stop_loss}\")\n",
    "                update_stop_loss(api, account_id, position['id'], new_stop_loss)\n",
    "\n",
    "def get_open_positions(api, account_id, pair):\n",
    "    # Fetch open positions from the account\n",
    "    response = api.request(v20.endpoints.positions.PositionDetails(accountID=account_id, instrument=pair))\n",
    "    return response['position']\n",
    "\n",
    "def get_current_price(api, pair):\n",
    "    # Fetch the current market price\n",
    "    response = api.request(v20.endpoints.pricing.PricingInfo(accountID=account_id, instruments=pair))\n",
    "    return float(response['prices'][0]['closeoutBid'])\n",
    "\n",
    "def update_stop_loss(api, account_id, order_id, new_stop_loss):\n",
    "    # Update the stop loss level for an open order\n",
    "    order_details = {\n",
    "        \"stopLossOnFill\": {\n",
    "            \"price\": new_stop_loss,\n",
    "            \"timeInForce\": \"GTC\"\n",
    "        }\n",
    "    }\n",
    "    request = v20.endpoints.orders.OrderReplace(accountID=account_id, orderID=order_id, data=order_details)\n",
    "    try:\n",
    "        api.request(request)\n",
    "        logging.info(f\"Stop loss updated for order {order_id} to {new_stop_loss}\")\n",
    "    except V20Error as e:\n",
    "        logging.error(f\"Failed to update stop loss for order {order_id}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "while True:\n",
    "    # Main execution\n",
    "    start_time = (datetime.now(timezone.utc) - timedelta(days=2)).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    end_time = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "    prices = fetch_forex_data(start_time, end_time, granularity, instrument)\n",
    "    # Your existing indicator calculations here...\n",
    "\n",
    "    # Analyze data and place orders based on predictions\n",
    "    analysis_result = analyze_data_with_gpt4o(indicators_summary, image_base64)\n",
    "    if analysis_result:\n",
    "        order_details = extract_and_place_order(analysis_result)\n",
    "        if order_details:\n",
    "            logging.info(\"Order placed based on analysis.\")\n",
    "\n",
    "    # Order management\n",
    "    monitor_and_manage_orders(api, account_id, pair)\n",
    "\n",
    "    logging.info(\"Waiting for 15 minutes before next run...\")\n",
    "    time.sleep(1500)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
